---
title: "Mission Control Explorations"
author: "Saptarshi Guha"
date: "`r Sys.Date()`"
output:
  html_document:
    toc: true
---


<style>
body {
    line-height: 1.4em;
    }>
.break-out {
    text-align: center;
    width: 100vw;
    position: relative;
    left: calc(-1 * (100vw - 100%)/2);
}
.r {
    background-color: white;
    border: 0;
        }

pre code, pre, code {
  white-space: pre !important;
  overflow-x: scroll !important;
  word-break: keep-all !important;
  word-wrap: initial !important;
}

</style>

```{r}
library(parallel)
library(brms)
library(glue)
library(data.table)
library(rjson)
library(future)
library(kableExtra)
library(reticulate)
plan(multicore)
slack.start() ##requires prefix.R
knitr::opts_chunk$set(eval=TRUE)

```

```{r eval=TRUE,echo=TRUE}
 
qr <- "
with
SAMPLING as (
 SELECT 'nightly' AS chan, 'Linux' as sos, 1 as NBUCKS
 UNION ALL
 SELECT 'nightly' AS chan, 'Darwin' as sos, 1 as NBUCKS
 UNION ALL
 SELECT 'nightly' AS chan, 'Windows_NT' as sos, 1 as NBUCKS
 UNION ALL
 SELECT 'beta' AS chan, 'Linux' as sos, 1 as NBUCKS
 UNION ALL
 SELECT 'beta' AS chan, 'Darwin' as sos, 1 as NBUCKS
 UNION ALL
 SELECT 'beta' AS chan, 'Windows_NT' as sos, 1 as NBUCKS
 UNION ALL
  SELECT 'release' AS chan, 'Linux' as sos, 1 as NBUCKS
 UNION ALL
 SELECT 'release' AS chan, 'Darwin' as sos, 1 as NBUCKS
 UNION ALL
 SELECT 'release' AS chan, 'Windows_NT' as sos, 3 as NBUCKS
),
a1 as (select
--- TOTAL USAGE ON FIREFOX
submission_date_s3 as date,
os,
sum(active_hours_sum) as usage_all,
count(distinct(client_id)) as dau_all
from telemetry.clients_daily_v6  HH left join SAMPLING
on HH.os = SAMPLING.sos and HH.normalized_channel = SAMPLING.chan
where
submission_date_s3 >='{current_version_release}'
and submission_date_s3 <= DATE_ADD(DATE '{current_version_release}', INTERVAL {nday} DAY)
and os  in ('Linux','Windows_NT','Darwin')
and app_name='Firefox'
and normalized_channel = '{norm_channel}'
-- and profile_creation_date>=12418 and profile_creation_date<=20089 
and  MOD(ABS(FARM_FINGERPRINT(MD5(client_id))), SAMPLING.NBUCKS)=0
group by 1,2
),
a2 as (
--- TOTAL USAGE ON FIREFOX ON LATEST VERSION
--- THIS AND THE ABOVE ARE USED FOR COMPUTING 'NVC'
select
submission_date_s3 as date,
os,
sum(active_hours_sum) as usage_cversion,
count(distinct(client_id)) as dau_cversion
from telemetry.clients_daily_v6 HH left join SAMPLING
on HH.os = SAMPLING.sos and HH.normalized_channel = SAMPLING.chan
where
submission_date_s3 >='{current_version_release}'
and submission_date_s3 <= DATE_ADD(DATE '{current_version_release}', INTERVAL {nday} DAY)
and os  in ('Linux','Windows_NT','Darwin')
and app_name='Firefox'
and normalized_channel = '{norm_channel}'
-- and profile_creation_date>=12418 and profile_creation_date<=20089 
and {app_version_field}='{current_version}'
and  MOD(ABS(FARM_FINGERPRINT(MD5(client_id))), SAMPLING.NBUCKS)=0
group by 1,2
),
A as (
select a1.date,a1.os,a1.usage_all, a1.dau_all, a2.usage_cversion, a2.dau_cversion
from a1 join a2
on a1.date =a2.date and a1.os=a2.os
),
b1 as (
--- Total Crashes on Current Version
--- NEED CLIENT_ID TO JOIN on DAILY TO GET CRASH RATE
select 
client_id,
submission_date as date,
os_name as os, 
sum(case when payload.processType IS NULL OR payload.processType = 'main' then 1 else 0 end) as cmain,
sum(case when payload.processType = 'content' and (udf.get_key(payload.metadata, 'ipc_channel_error') is null or (udf.get_key(payload.metadata, 'ipc_channel_error') is not null  and udf.get_key(payload.metadata, 'ipc_channel_error') !='ShutdownKill')) then 1 else 0 end) as ccontent
from {crash_src} JJ left join SAMPLING
on JJ.os_name = SAMPLING.sos and JJ.normalized_channel = SAMPLING.chan
where submission_date >='{current_version_release}'
and submission_date <= DATE_ADD(DATE '{current_version_release}', INTERVAL {nday} DAY)
and os_name in ('Linux','Windows_NT','Darwin')
and application='Firefox'
and normalized_channel = '{norm_channel}'
and {build_version_field} in ('{current_version_crash}')
and profile_created>=12418 and profile_created<=20089 
and  MOD(ABS(FARM_FINGERPRINT(MD5(client_id))), SAMPLING.NBUCKS)=0
group by 1,2,3
),
--- TOTAL HOURS FROM FOLKS WHO CRASHED
--- TO COMPUTE CRASH RATE 
b2 as (select
client_id,
submission_date_s3 as date,
os as os,
sum(active_hours_sum) as usage,
sum(coalesce(crashes_detected_plugin_sum,0)) as cplugin
from telemetry.clients_daily_v6 HH left join SAMPLING
on HH.os = SAMPLING.sos and HH.normalized_channel = SAMPLING.chan
where
submission_date_s3 >='{current_version_release}'
and submission_date_s3 <= DATE_ADD(DATE '{current_version_release}', INTERVAL {nday} DAY)
and os  in ('Linux','Windows_NT','Darwin')
and app_name='Firefox'
and normalized_channel = '{norm_channel}'
and {app_version_field}='{current_version}'
-- and profile_creation_date>=12418 and profile_creation_date<=20089 
and  MOD(ABS(FARM_FINGERPRINT(MD5(client_id))), SAMPLING.NBUCKS)=0
group by 1,2,3
),
b as (
select 
b1.date,b1.os, 
count(distinct(case when b1.cmain>0 then b1.client_id else null end)) as dau_cm_crasher_cversion,
count(distinct(case when b1.ccontent>0  then b1.client_id else null end)) as dau_cc_crasher_cversion,
count(distinct(case when b2.cplugin>0 then b1.client_id else null end)) as dau_cp_crasher_cversion,
count(distinct(case when (b1.cmain>0 or b1.ccontent>0  or b2.cplugin>0)
                        then b1.client_id else null end)) as dau_call_crasher_cversion,
sum(case when b1.cmain>0 then b2.usage else 0 end) as usage_cm_crasher_cversion,
sum(case when b1.ccontent >0  then b2.usage else 0 end) as usage_cc_crasher_cversion,
sum(case when b2.cplugin >0 then b2.usage else 0 end) as usage_cp_crasher_cversion,
sum(case when (b1.cmain>0 or b1.ccontent>0 or b2.cplugin >0) then b2.usage else 0 end) as usage_call_crasher_cversion,
sum(cmain) as cmain,
sum(ccontent)  as ccontent,
sum(cplugin) as cplugin,
sum(cmain)+sum(ccontent) + sum(cplugin) as call
from b1 join b2 
on b1.client_id = b2.client_id and b1.os=b2.os and b1.date = b2.date
group by 1,2
),
d as (
select
A.date,A.os,A.usage_all, A.dau_all, A.usage_cversion, A.dau_cversion,
b.dau_cm_crasher_cversion,b.dau_cc_crasher_cversion,b.dau_cp_crasher_cversion,b.dau_call_crasher_cversion,
b.usage_cm_crasher_cversion,b.usage_cc_crasher_cversion,b.usage_cp_crasher_cversion,b.usage_call_crasher_cversion,
b.cmain,b.ccontent,b.cplugin,b.call
from b join A
on b.date=A.date and b.os=A.os
)
select * from d order by os, date
"
```

## RELEASE DATA

```{r}
library(glue) 
library(data.table)
isn <- function(s,r = 'telemetry.crash_summary_v1') if(is.null(s) || length(s)==0) r else s

fxv <- local({
  r <- fromJSON(file="https://product-details.mozilla.org/1.0/firefox.json")
  rbindlist(lapply(r$releases,function(s){
    data.table(build.number=s$build_number, categ=s$category, date=as.Date(s$date),
               description = isn(s$description,NA), is.security = s$is_security_driven,
               product = s$product,version=s$version)
  }))
})

fxv.releases <- fxv[grepl("(major|stability)",categ),][date >='2019-01-01',]
fxv.releases <- fxv.releases[, ":="(major = as.numeric(sapply(version,function(s) head(strsplit(s,"\\.")[[1]],1))),
                                    minor = as.numeric(sapply(version,function(s) tail(strsplit(s,"\\.")[[1]],1))))]
fxv.releases <- fxv.releases[order(major,minor),]
release.the.current.release <- tail(fxv.releases,1)[, list(version, major,minor, date)]
release.releases.for.model <- fxv.releases[major %in% c(release.the.current.release$major,release.the.current.release$major-1,release.the.current.release$major-2),]


release.what.i.need <- fxv.releases[major %in% release.the.current.release$major,]
release.what.i.need <- release.what.i.need[,list(v=version,d=date, till=date, c='release',ndays=72, crash_src='telemetry.crash_summary_v2',
                                                                         app_version_field='app_version', build_version_field='build_version')]
release.what.i.need$till= c(tail(release.what.i.need$d,-1),Sys.Date()+365)
g <- bq()

```


```{r getData1,cache=TRUE,results='hide',message=FALSE, warning=FALSE}
add_fields <- function(x, current_version, d,till ){
  x <- x[,":="(date=as.Date(date))]
  x[,":="(date=as.Date(date),c_version = current_version, c_version_rel = as.Date(d), isLatest=date<=till,t =as.numeric(date - as.Date(d)))][,]
  x<- x[, ":="(
    cmi=  (1+dau_cm_crasher_cversion)/dau_cversion,
    cmr = (1+cmain) / sapply(usage_cm_crasher_cversion,function(s) {if( s< 60/3600){ 0 } else{ s}}),
    cci = (1+dau_cc_crasher_cversion)/dau_cversion,
    ccr = (1+ccontent)/sapply(usage_cc_crasher_cversion,function(s) {if( s< 60/3600){ 0 } else{ s}}),
    nvc=usage_cversion/usage_all,
    os=factor(os, levels=c("Linux","Darwin","Windows_NT")),
    c_version_rel = as.Date(c_version_rel)
  )]
  x
}


######################################################################
## GET NEW DATA FOR CURRENT MAJOR FOR RELEASE
######################################################################

dall.release.new <-   release.what.i.need[,{
    print(.SD);print(.BY)
    qf <- glue(qr,
               current_version=.BY$v,
               current_version_crash=.BY$v,
               current_version_release=d,
               norm_channel = c,
               app_version_field = app_version_field,
               build_version_field=build_version_field,
               nday=ndays,
               crash_src=isn(crash_src),
               NBUCKS=1
              )
    qff <- g$q(qf,-1)
    if(nrow(qff) > 0)
      add_fields(qff,.BY$v,d,till)
},by=v]

dall.release.new <- dall.release.new[, {
  ## Take the last day we saw the max
  index <- which.max(nvc)
  s <- (1:.N)[ isLatest]
  if(length(s) > 0){
   whenStoppedBeingLatest <- max( s )
  } else whenStoppedBeingLatest <- -1
  if(index<whenStoppedBeingLatest) index <- whenStoppedBeingLatest
  .SD[1:whenStoppedBeingLatest,]
  .SD[1:index,]
},by=list(os,c_version)]

dall.release.new <- dall.release.new[, ":="( major = as.numeric(sapply(c_version,function(s) head(strsplit(s,"\\.")[[1]],1))),
                                            minor = as.numeric((sapply(c_version,function(s) tail(strsplit(s,"\\.")[[1]],1)))))]

```

## BETA: DATA

FOR BETA NOW: GET BUILD MAPPING WHICH WILL GET REPLACED BY PYTHON CODE

```{r getBetaData}

buildhub <- import("buildhub_bid")
builds <- local({
  x <-  buildhub$pull_build_id_docs()
  x <- buildhub$version2build_ids(x)
  x=rbindlist(Map(function(n,b){
    data.table(versions=n, buildid=paste(b,collapse=","))
  },names(x),x))[order(versions),]
})
  

######################################################################
## GET OLD DATA FROM BQ
## NEEDED FOR MODEL
######################################################################

fxv.beta <- fxv[grepl("(dev)",categ),][date >='2019-01-01',]
fxv.beta <- fxv.beta[, ":="( major=  as.numeric(sapply(version,function(s) head(strsplit(s,"\\.0b")[[1]],1))),
                            minor = as.numeric(sapply(version,function(s) tail(strsplit(s,"\\.0b")[[1]],1))))]
fxv.beta <- fxv.beta[order(major,minor),]
beta.the.current.release <- tail(fxv.beta,1)[, list(version, major,minor, date)]
beta.releases.for.model <- fxv.beta[major %in% c(beta.the.current.release$major,beta.the.current.release$major-1,beta.the.current.release$major-2),]

beta.what.i.need <- fxv.beta[major %in% beta.the.current.release$major,][,list(v=version,d=date, till=date, c='beta',ndays=14, crash_src='telemetry.crash_summary_v2',
                                                                         app_version_field='app_display_version', build_version_field='build_id')]
beta.what.i.need$till= c(tail(beta.what.i.need$d,-1),Sys.Date()+7)
beta.what.i.need <- merge(beta.what.i.need,builds[, list(v=versions, buildid)],by=c('v'),all.x=TRUE)
```

```{r betadata}
dall.beta.new <-   beta.what.i.need[,{
    print(.SD);print(.BY)
    qf <- glue(qr,
               current_version=.BY$v,
               current_version_crash=buildid,
               current_version_release=d,
               norm_channel = c,
               app_version_field = app_version_field,
               build_version_field=build_version_field,
               nday=ndays,
               crash_src=isn(crash_src),
               NBUCKS=1
              )
    qff <- g$q(qf,-1)
    if(nrow(qff) > 0)
      add_fields(qff,.BY$v,d,till)
},by=v]

dall.beta.new <- dall.beta.new[, {
  ## Take the last day we saw the max
  index <- which.max(nvc)
  s <- (1:.N)[ isLatest]
  if(length(s) > 0){
   whenStoppedBeingLatest <- max( s )
  } else whenStoppedBeingLatest <- -1
  if(index<whenStoppedBeingLatest) index <- whenStoppedBeingLatest
  .SD[1:whenStoppedBeingLatest,]
  .SD[1:index,]
},by=list(os,c_version)]
dall.beta.new <- dall.beta.new[,":="( major=  as.numeric(sapply(c_version,function(s) head(strsplit(s,"\\.0b")[[1]],1))),
                                      minor = as.numeric(sapply(c_version,function(s) tail(strsplit(s,"\\.0b")[[1]],1))))]
dall.new <- rbind(dall.beta.new[,":="(channel='beta')],dall.release.new[,":="(channel='release')])[,":="(v=NULL)]

```


```{r writeData}
## What versions, channels, and os did we read today?
unq <- dall.new[, list(n=.N),by=list(major, channel)]

## delete them from BQ table
res <- unq[,{
  del.q <- glue("delete  from analysis.sguha_crash_rate_raw  where major={major} and channel='{channel}'",major=major, channel=.BY$channel)
  g$q(del.q)
},by=channel]

## Upload new data
atemp <- tempfile()
write.csv(dall.new, file=atemp)
system(glue("bq load --noreplace --project_id moz-fx-data-derived-datasets --source_format=CSV --skip_leading_rows=1 --null_marker=NA",
            " analysis.sguha_crash_rate_raw {atemp}"))

## Created FIRST TABLE via
## bq load --autodetect --source_format=CSV --project_id moz-fx-data-derived-datasets --skip_leading_rows=1 --null_marker=NA analysis.sguha_crash_rate_raw ~/tmp/dall.all

```





## GET MODEL DATA


Current and last two versions:

```{r}
dall.rel2 <- g$q(glue("select * from analysis.sguha_crash_rate_raw where channel = 'release' and major in ({whichv})",
         whichv = paste(unique(release.releases.for.model[,major]),collapse=",")),-1)
dall.rel2 <- dall.rel2[nvc > 0][,":="(cmi.logit=boot::logit(cmi),cci.logit=boot::logit(cci),nvc.logit=boot::logit(nvc),cmr.wt = 1*(cmain >0), ccr.wt = 1*(ccontent > 0))]

dall.beta2 <- g$q(glue("select * from analysis.sguha_crash_rate_raw where channel = 'beta' and major in ({whichv})",
         whichv = paste(unique(beta.releases.for.model[,major]),collapse=",")),-1)
dall.beta2 <- dall.beta2[nvc > 0][,":="(cmi.logit=boot::logit(cmi),cci.logit=boot::logit(cci),nvc.logit=boot::logit(nvc),cmr.wt = 1*(cmain >0), ccr.wt = 1*(ccontent > 0))]

dall.rel2[, wts := nvc/sum(nvc)*100*3,by=os]
dall.beta2[, wts :=  nvc/sum(nvc)*100*3,by=os]

```


## BUILD MODELS

```{r}

ffunc <- function(M,D)  brm(M,data=D, chains = 4, control = list(adapt_delta = 0.999, max_treedepth=12), cores = 4)
      # M0 <- bf( log(1+cmain) | weights(cmr.wt)   ~  os + os*poly(log(usage_cm_crasher_cversion+1/60),2)+os*poly(nvc.logit,2)  + (1+os|c_version), sigma ~   os + s(nvc.logit, m=1))
make.a.model <- function(data,wh,skew=FALSE){
  if(wh=="cmr"){
    M0 <- bf( log(cmain+1) |weights(cmr.wt)   ~  os+offset(log( usage_cm_crasher_cversion+1/60))  + s(nvc,m=1,by=os) + (1+os|c_version), sigma ~ os+s(nvc,m=1)) 
    if(alter){
      M0 <- bf( cmain+1 |weights(cmr.wt)   ~  os+offset(log( usage_cm_crasher_cversion+1/60))  + s(nvc,m=1,by=os)+(1+os|c_version), shape ~ os+s(nvc,m=1))+negbinomial()
    }
  }
  if(wh=='ccr'){
    M0 <- bf( log(ccontent+1) | weights(ccr.wt)   ~  os+offset(log( usage_cc_crasher_cversion+1/60))  + s(nvc,m=1,by=os) + (1+os|c_version), sigma ~ os+s(nvc,m=1))
    if(alter){
      M0 <- bf( ccontent+1 | weights(ccr.wt)   ~  os+offset(log( usage_cc_crasher_cversion+1/60))  + s(nvc,m=1,by=os) + (1+os|c_version), shape ~  os+s(nvc,m=1))+negbinomial()
    }
  }
  if(wh=='cmi'){
    #M0<- bf( log(1+dau_cm_crasher_cversion)   ~   os+ offset(log( dau_cversion)) + s(nvc,m=1,by=os) + (1+os|c_version), sigma ~ os+s(nvc,m=1))
    M0<- bf( cmi.logit   ~   os + s(nvc,m=1,by=os) + (1+os|c_version), sigma ~ os+s(nvc,m=1))
  }
  if(wh=='cci'){
    #M0<- bf( log(1+dau_cc_crasher_cversion)   ~   os+ offset(log( dau_cversion))  + s(nvc,m=1,by=os) + (1+os|c_version), sigma ~ os+s(nvc,m=1))
    M0<- bf( cci.logit   ~   os  + s(nvc,m=1,by=os) + (1+os|c_version), sigma ~ os+s(nvc,m=1))
  }
  ffunc(M0,data)
}

Predict <- function(M,...){
  p <- predict(M,...)
  fa <- family(M)$fam
  if(fa=="gaussian") return(p)
  if(fa=="negbinomial") {return(log(p))}
}
    
  
getPredictions <- function(M,D, wh,givenx=NULL,COUNT=FALSE){
  if(is.null(givenx)){
    x <-Predict(M,newdata=D,summary=FALSE)
  }else{
    x <-givenx
  }
  if(COUNT){
    return (exp(t(x)-1))
  }
  if(wh=='cmr'){
    r <- exp( t(x) - D[, log( usage_cm_crasher_cversion+1/60)])
  }
  if(wh=='ccr'){
    r <- exp(t(x) -  D[, log( usage_cc_crasher_cversion+1/60)])
  }
  if(wh=='cmi'){
    #r <- exp(t(x) -  D[, log( dau_cversion)])
    r <- boot::inv.logit(t(x))
    }
  if(wh=='cci'){
    #r <- exp(t(x) - D[, log( dau_cversion)])
    r <- boot::inv.logit(t(x))
  }
  r
}
 
```

Release model

```{r releaseModel}
slackr("RELEASE CHAINS STARTING")
d.rel <- dall.rel2
cr.cm.rel.f <- future({ make.a.model(d.rel,'cmr') })
cr.cc.rel.f <- future({ make.a.model(d.rel,'ccr') })
ci.cm.rel.f <- future({ make.a.model(d.rel,'cmi') })
ci.cc.rel.f <- future({ make.a.model(d.rel,'cci') })

cr.cm.rel <- value(cr.cm.rel.f)
cr.cc.rel <- value(cr.cc.rel.f)
ci.cm.rel <- value(ci.cm.rel.f)
ci.cc.rel <- value(ci.cc.rel.f)
slackr("RELEASE CHAINS DONE")
```

Beta Model

```{r betaModel}
slackr("BETA CHAINS STARTING")
d.beta <- dall.beta2
cr.cm.beta.f <- future({ make.a.model(d.beta,'cmr') })
cr.cc.beta.f <- future({ make.a.model(d.beta,'ccr') })
ci.cm.beta.f <- future({ make.a.model(d.beta,'cmi') })
ci.cc.beta.f <- future({ make.a.model(d.beta,'cci') })
cr.cm.beta <- value(cr.cm.beta.f)
cr.cc.beta <- value(cr.cc.beta.f)
ci.cm.beta <- value(ci.cm.beta.f)
ci.cc.beta <- value(ci.cc.beta.f)
slackr("BETA CHAINS DONE!")
```


I use a 1% trimmed mean because some of the posteriors especially when nvc is
small have crazy large outliers.

```{r}
TR <- 1/100/2
CENT <- function(s)  mean(s, trim=TR)
getLowsAndHighs <- function(D,mdl.rm,mdl.rc,mdl.im,mdl.ic){
  getLowHi <- function(x,names,trans){
    x <- rbindlist(apply(x,1,function(s){
      data.table(lo90 = trans(quantile(s,0.05)), mean = CENT(trans(s)), hi90=quantile(trans(s),0.95))
    }))
    setnames(x,names)
  }
  pm <- getPredictions(mdl.rm, D, 'cmr')
  pc <- getPredictions(mdl.rc, D, 'ccr')
  cmrpreds <- getLowHi(pm,trans=function(s) s,names=c("cmr.lo90","cmr.mean","cmr.hi90"))
  ccrpreds <- getLowHi(pc,trans=function(s) s,names=c("ccr.lo90","ccr.mean","ccr.hi90"))
  cavgrpreds <- getLowHi((pm+pc)/2,trans=function(s) s,names=c("cavgr.lo90","cavgr.mean","cavgr.hi90"))
  pm <- getPredictions(mdl.im, D, 'cmi')
  pc <- getPredictions(mdl.ic, D, 'cci')
  cmipreds <- getLowHi(pm,trans=function(s) s,names=c("cmi.lo90","cmi.mean","cmi.hi90"))
  ccipreds <- getLowHi(pc,trans=function(s) s,names=c("cci.lo90","cci.mean","cci.hi90"))
  cavgipreds <- getLowHi((pm+pc)/2,trans=function(s) s,names=c("cavgi.lo90","cavgi.mean","cavgi.hi90"))
  cbind(cmrpreds,ccrpreds,cavgrpreds, cmipreds, ccipreds, cavgipreds)
}

CENT <- function(s)  mean(s, trim=TR)
getBetaTrend <- function(D,mdl.rm,mdl.rc,mdl.im,mdl.ic){
  getLowHi <- function(x,names,trans){
    x <- rbindlist(apply(x,1,function(s){
      data.table(lo90 = trans(quantile(s,0.05)), mean = CENT(trans(s)), hi90=quantile(trans(s),0.95))
    }))
    setnames(x,names)
  }
  cversions  = D[, list(l=1),by=list(os,c_version)][,l := NULL]
  pm <- cbind(D[, list(os,c_version, usage_cm_crasher_cversion)],data.table(getPredictions(mdl.rm, D, 'cmr',COUNT=TRUE)))[, {
    f <- data.table(t(apply(.SD,2,sum,drop=FALSE)))
    (1+f[,2:ncol(f), with=FALSE])/ (1/60+f[,1,with=FALSE][[1]])
  },   by=list(os,c_version)][, ":="(c_version = NULL, os=NULL)]
  print("cmr done")
  pc <- cbind(D[, list(os,c_version, usage_cc_crasher_cversion)],data.table(getPredictions(mdl.rc, D, 'ccr',COUNT=TRUE)))[, {
    f <- data.table(t(apply(.SD,2,sum,drop=FALSE)))
    (1+f[,2:ncol(f), with=FALSE])/ (1/60+f[,1,with=FALSE][[1]])
  },   by=list(os,c_version)][, ":="(c_version = NULL, os=NULL)]
  print("ccr done")
  cmrpreds <- getLowHi(pm,trans=function(s) s,names=c("cmr.lo90","cmr.mean","cmr.hi90"))
  ccrpreds <- getLowHi(pc,trans=function(s) s,names=c("ccr.lo90","ccr.mean","ccr.hi90"))
  cavgrpreds <- getLowHi((pm+pc)/2,trans=function(s) s,names=c("cavgr.lo90","cavgr.mean","cavgr.hi90"))
  pm <- cbind(D[, list(os,c_version, dau_cversion)],data.table(getPredictions(mdl.im, D, 'cmi',COUNT=TRUE)))[, {
    f <- data.table(t(apply(.SD,2,sum,drop=FALSE)))
    (1+f[,2:ncol(f), with=FALSE])/ f[,1,with=FALSE][[1]]
  },   by=list(os,c_version)][, ":="(c_version = NULL, os=NULL)]
  print("cmi done")
  pc <- cbind(D[, list(os,c_version,dau_cversion )],data.table(getPredictions(mdl.ic, D, 'cci',COUNT=TRUE)))[, {
    f <- data.table(t(apply(.SD,2,sum,drop=FALSE)))
    (1+f[,2:ncol(f), with=FALSE])/ f[,1,with=FALSE][[1]]
  },   by=list(os,c_version)][, ":="(c_version = NULL, os=NULL)]
  print("cci done")
  cmipreds <- getLowHi(pm,trans=function(s) s,names=c("cmi.lo90","cmi.mean","cmi.hi90"))
  ccipreds <- getLowHi(pc,trans=function(s) s,names=c("cci.lo90","cci.mean","cci.hi90"))
  cavgipreds <- getLowHi((pm+pc)/2,trans=function(s) s,names=c("cavgi.lo90","cavgi.mean","cavgi.hi90"))
  cbind(cversions,cmrpreds,ccrpreds,cavgrpreds, cmipreds, ccipreds, cavgipreds)
}

getRelDiff <- function(crm.model,crc.model,cim.model,cic.model,current.data,current.data.modified,CUT=0.35,CUT.I=0.15){
  H <- function(S,names,CUT=CUT){
    x <- data.table(h=apply(S,1,function(s) { a <-mean(s > CUT); if(is.na(a)) 0 else a}))
    setnames(x,names)
    x
  }
  tvm <- getPredictions(NULL, current.data,'cmr',given=Predict(crm.model,summary=FALSE, newdata=current.data))
  pvm <- getPredictions(NULL, current.data.modified, 'cmr',given=Predict(crm.model,summary=FALSE, newdata=current.data.modified))
  tvc <- getPredictions(NULL, current.data, 'ccr', given=Predict(crc.model,summary=FALSE, newdata=current.data))
  pvc <- getPredictions(NULL, current.data.modified, 'ccr', given=Predict(crc.model,summary=FALSE, newdata=current.data.modified))
  trans <- function(s) s  #function(x) x
  cmr=H(  (trans(tvm) - trans(pvm))/trans(pvm),names=c("cmr.reg.prob"))
  ccr=H(  (trans(tvc) - trans(pvc))/trans(pvc),names=c("ccr.reg.prob"))
  tv1 <- (tvc+tvm)/2;pv1 <- (pvc+pvm)/2
  cavgr <- H( (trans(tv1) - trans(pv1))/trans(pv1),names=c("cavgr.reg.prob"))
  tvm <- getPredictions(NULL, current.data,'cmr',given=Predict(cim.model,summary=FALSE, newdata=current.data))
  pvm <- getPredictions(NULL, current.data.modified, 'cmr',given=Predict(cim.model,summary=FALSE, newdata=current.data.modified))
  tvc <- getPredictions(NULL, current.data, 'ccr', given=Predict(cic.model,summary=FALSE, newdata=current.data))
  pvc <- getPredictions(NULL, current.data.modified, 'ccr', given=Predict(cic.model,summary=FALSE, newdata=current.data.modified))
  trans <- function(x) x
  cmi=H(  (trans(tvm) - trans(pvm))/trans(pvm),names=c("cmi.reg.prob"),CUT=CUT.I)
  cci=H(  (trans(tvc) - trans(pvc))/trans(pvc),names=c("cci.reg.prob"),CUT=CUT.I)
  tv1 <- (tvm+tvc)/2;pv1 <- (pvm+pvc)/2
  cavgi <- H( (trans(tv1) - trans(pv1))/trans(pv1),names=c("cavgi.reg.prob"),CUT=CUT.I)
  cbind(current.data[,list(os,date,c_version)],cmr, ccr,cavgr, cmi,cci,cavgi)
}

```




For Release data structures


```{r releaseDataStructure}
release.releases.for.model <- release.releases.for.model[order(major,minor),]
rel.current.version <- tail(release.releases.for.model,2)[2,version]
rel.prev.version <- tail(release.releases.for.model,2)[1,version]
rel.current.data <- d.rel[c_version==rel.current.version,][order(os, date),]
rel.current.data.modified <- data.table(data.frame(rel.current.data))[, c_version := rel.prev.version]

lowhigh.rel <- getLowsAndHighs(d.rel,cr.cm.rel,cr.cc.rel,ci.cm.rel,ci.cc.rel)
reldiff.rel <- getRelDiff(cr.cm.rel,cr.cc.rel,ci.cm.rel,ci.cc.rel, rel.current.data,rel.current.data.modified)

rel.posts <- cbind(d.rel[,list(date,cmr.wt,ccr.wt,c_version, os,nvc,cmr,ccr,cmi,cci)],lowhigh.rel)
rel.posts <- merge(rel.posts,reldiff.rel,all.x=TRUE,by=c("os","date","c_version"))

rel.summary <- rel.posts[c_version==rel.current.version,][date==max(date),]

H0 <- function(nvc,l,h){
  return( nvc > 0.2)
}
SPAN_L <- 2
rel.posts <- merge(rel.posts,rel.posts[,{
  i <- 1:.N
  cavgr <- (cmr+ccr)/2; cavgi <- (cmi+cci)/2
  cmr.fit <- loess(cmr.mean  ~ i,span=SPAN_L,weights=H0(nvc,cmr.lo90,cmr.hi90))$fitted
  ccr.fit <- loess(ccr.mean ~ i, span=SPAN_L, weights=H0(nvc,ccr.lo90,ccr.hi90))$fitted
  cavgr.fit <- loess(cavgr.mean ~ i, span=SPAN_L, weights=H0(nvc,cavgr.lo90,cavgr.hi90))$fitted
  cmi.fit <- loess(cmi.mean  ~ i, span=SPAN_L, weights=H0(nvc,cmi.lo90,cmi.hi90))$fitted
  cci.fit <- loess(cci.mean ~ i, span=SPAN_L, weights=H0(nvc,cci.lo90,cci.hi90))$fitted
  cavgi.fit <- loess(cavgi.mean ~ i, span=SPAN_L, weights=H0(nvc,cavgi.lo90,cavgi.hi90))$fitted
  list(date=date,c_version=c_version,cmr.loess=cmr.fit,
       ccr.loess=ccr.fit, cavgr.loess=cavgr.fit,
       cmi.loess=cmi.fit, cci.loess=cci.fit, cavgi.loess=cavgi.fit)
  }, by=os], by=c("os","date","c_version"))

```

For beta data structures

```{r betaDataStructure}
beta.releases.for.model <- beta.releases.for.model[order(major,minor),]
beta.current.version <- tail(beta.releases.for.model,2)[2,version] 
beta.prev.version <-  tail(beta.releases.for.model,2)[1,version]
beta.current.major <- tail(beta.releases.for.model,2)[2,major]
beta.prev.major <- beta.current.major-1
beta.current.data <- d.beta[c_version==beta.current.version,][order(os, date),]
beta.current.data.modified <- data.table(data.frame(beta.current.data))[, c_version := beta.prev.version]

lowhigh.beta <- getLowsAndHighs(d.beta,cr.cm.beta,cr.cc.beta,ci.cm.beta,ci.cc.beta)
reldiff.beta <- getRelDiff(cr.cm.beta,cr.cc.beta,ci.cm.beta,ci.cc.beta, beta.current.data,beta.current.data.modified)
beta.posts <- cbind(d.beta[,list(date,cmr.wt,ccr.wt,c_version, os,nvc,cmr,ccr,cmi,cci)],lowhigh.beta)
beta.posts <- merge(beta.posts,reldiff.beta,all.x=TRUE,by=c("os","date","c_version"))

beta.summary <- beta.posts[c_version==beta.current.version,][date==max(date),]
beta.trend3 <- getBetaTrend(d.beta,cr.cm.beta,cr.cc.beta,ci.cm.beta,ci.cc.beta)
beta.trend3[, ":="(major =  (sapply(c_version,function(s) head(strsplit(s,"\\.0b")[[1]],1))),
                   minor = (sapply(c_version,function(s) tail(strsplit(s,"\\.0b")[[1]],1))))]
beta.trend2 <- beta.trend3[major %in% c(beta.current.major,beta.prev.major),][order(os,as.numeric(as.character(major)),as.numeric(as.character(minor))),]
beta.trend2 <- merge(beta.trend2,  beta.posts[, {
  tail(.SD,1)[, list(nvc=nvc)]
},by=list(os,c_version)], by=c("os","c_version"))[order(os,as.numeric(as.character(major)),as.numeric(as.character(minor))),]

```


## SAVE
```{r eval=TRUE}
zq <- expression({
  
  u <- getwd()
  setwd("visual_demo/data/")
  write.csv(rel.posts, "rel.posts.csv")
  write.csv(rel.summary,"rel.summary.csv")
  write.csv(beta.posts,"beta.posts.csv")
  write.csv(beta.summary,"beta.summary.csv")
  write.csv(beta.trend2, "beta.trend.csv")
  setwd(u);rm(u)
  
  clean_site("./visual_demo")
  render_site("./visual_demo/")
  
  system(glue("mkdir -p ./visual_demo/older/{today}/", today=(j <- Sys.Date())))
  system(glue("rsync -avz ./visual_demo/_site/ ./visual_demo/older/{today}/",today=j))
  system("rsync -av ~/mz/missioncontrol/ex1/visual_demo/ ~/pubsguha/visual_demo/")
  system("ls ~/pubsguha/visual_demo/older/ | cat ~/pubsguha/visual_demo/older/index.html")
  system("ls ~/pubsguha/visual_demo/older/ > ~/pubsguha/visual_demo/older/index.html")
  system("ls ~/pubsguha/visual_demo/data/ > ~/pubsguha/visual_demo/data/index.html")
})
```

```{r eval=FALSE}

#alter=TRUE;render("report.3.Rmd");
clean_site("./visual_demo");  render_site("./visual_demo/")a
alter=TRUE;render("report.3.Rmd");
eval(zq)


```

## PLOTS

### Crash Rate

```{r pp3}

pp_check(cr.cc.rel, type='stat_grouped', group='os')
pp_check(cr.cm.rel, type='stat_grouped', group='os')
pp_check(cr.cm.beta, type='stat_grouped', group='os')
pp_check(cr.cc.beta, type='stat_grouped', group='os')
```


### Crash Incidence

```{r pp2}
pp_check(ci.cm.rel, type='stat_grouped', group='os')
pp_check(ci.cc.rel, type='stat_grouped', group='os')
pp_check(ci.cm.beta, type='stat_grouped', group='os') 
pp_check(ci.cc.beta, type='stat_grouped', group='os')
```

### Correlations

```{r}

rel.posts[!is.na(cmr) & cmr !=Inf, cor(cmr,cmr.mean),by=os]
rel.posts[!is.na(ccr) & ccr !=Inf ,cor(ccr,ccr.mean),by=os]
beta.posts[!is.na(cmr) & cmr !=Inf,cor(cmr,cmr.mean),by=os]
beta.posts[!is.na(ccr) & ccr !=Inf,cor(ccr,ccr.mean),by=os]


rel.posts[,cor(cmi,cmi.mean),by=os]
rel.posts[,cor(cci,cci.mean),by=os]
beta.posts[,cor(cmi,cmi.mean),by=os]
beta.posts[,cor(cci,cci.mean),by=os]

```
