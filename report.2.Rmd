---
title: "Mission Control Explorations"
author: "Saptarshi Guha"
date: "`r Sys.Date()`"
output:
  html_document:
    toc: true
---


<style>
body {
    line-height: 1.4em;
    }>
.break-out {
    text-align: center;
    width: 100vw;
    position: relative;
    left: calc(-1 * (100vw - 100%)/2);
}
.r {
    background-color: white;
    border: 0;
        }

pre code, pre, code {
  white-space: pre !important;
  overflow-x: scroll !important;
  word-break: keep-all !important;
  word-wrap: initial !important;
}

</style>

This is work for [this](https://docs.google.com/document/d/1xfGbJw90hRHdlg-dd0flAK5KlOLIElH1IRnxW7lll98/edit#)
Google doc.

```{r}
knitr::opts_chunk$set(eval=FALSE)
```

```{r eval=TRUE,echo=TRUE}
 
qr <- "
with
SAMPLING as (
 SELECT 'nightly' AS chan, 'Linux' as sos, 1 as NBUCKS
 UNION ALL
 SELECT 'nightly' AS chan, 'Darwin' as sos, 1 as NBUCKS
 UNION ALL
 SELECT 'nightly' AS chan, 'Windows_NT' as sos, 1 as NBUCKS
 UNION ALL
 SELECT 'beta' AS chan, 'Linux' as sos, 1 as NBUCKS
 UNION ALL
 SELECT 'beta' AS chan, 'Darwin' as sos, 1 as NBUCKS
 UNION ALL
 SELECT 'beta' AS chan, 'Windows_NT' as sos, 1 as NBUCKS
 UNION ALL
  SELECT 'release' AS chan, 'Linux' as sos, 1 as NBUCKS
 UNION ALL
 SELECT 'release' AS chan, 'Darwin' as sos, 1 as NBUCKS
 UNION ALL
 SELECT 'release' AS chan, 'Windows_NT' as sos, 3 as NBUCKS
),
a1 as (select
--- TOTAL USAGE ON FIREFOX
submission_date_s3 as date,
os,
sum(active_hours_sum) as usage_all,
count(distinct(client_id)) as dau_all
from telemetry.clients_daily_v6  HH left join SAMPLING
on HH.os = SAMPLING.sos and HH.normalized_channel = SAMPLING.chan
where
submission_date_s3 >='{current_version_release}'
and submission_date_s3 <= DATE_ADD(DATE '{current_version_release}', INTERVAL {nday} DAY)
and os  in ('Linux','Windows_NT','Darwin')
and app_name='Firefox'
and normalized_channel = '{norm_channel}'
-- and profile_creation_date>=12418 and profile_creation_date<=20089 
and  MOD(ABS(FARM_FINGERPRINT(MD5(client_id))), SAMPLING.NBUCKS)=0
group by 1,2
),
a2 as (
--- TOTAL USAGE ON FIREFOX ON LATEST VERSION
--- THIS AND THE ABOVE ARE USED FOR COMPUTING 'NVC'
select
submission_date_s3 as date,
os,
sum(active_hours_sum) as usage_cversion,
count(distinct(client_id)) as dau_cversion
from telemetry.clients_daily_v6 HH left join SAMPLING
on HH.os = SAMPLING.sos and HH.normalized_channel = SAMPLING.chan
where
submission_date_s3 >='{current_version_release}'
and submission_date_s3 <= DATE_ADD(DATE '{current_version_release}', INTERVAL {nday} DAY)
and os  in ('Linux','Windows_NT','Darwin')
and app_name='Firefox'
and normalized_channel = '{norm_channel}'
-- and profile_creation_date>=12418 and profile_creation_date<=20089 
and {app_version_field}='{current_version}'
and  MOD(ABS(FARM_FINGERPRINT(MD5(client_id))), SAMPLING.NBUCKS)=0
group by 1,2
),
A as (
select a1.date,a1.os,a1.usage_all, a1.dau_all, a2.usage_cversion, a2.dau_cversion
from a1 join a2
on a1.date =a2.date and a1.os=a2.os
),
b1 as (
--- Total Crashes on Current Version
--- NEED CLIENT_ID TO JOIN on DAILY TO GET CRASH RATE
select 
client_id,
submission_date as date,
os_name as os, 
sum(case when payload.processType IS NULL OR payload.processType = 'main' then 1 else 0 end) as cmain,
sum(case when payload.processType = 'content' and (udf.get_key(payload.metadata, 'ipc_channel_error') is null or (udf.get_key(payload.metadata, 'ipc_channel_error') is not null  and udf.get_key(payload.metadata, 'ipc_channel_error') !='ShutdownKill')) then 1 else 0 end) as ccontent
from {crash_src} JJ left join SAMPLING
on JJ.os_name = SAMPLING.sos and JJ.normalized_channel = SAMPLING.chan
where submission_date >='{current_version_release}'
and submission_date <= DATE_ADD(DATE '{current_version_release}', INTERVAL {nday} DAY)
and os_name in ('Linux','Windows_NT','Darwin')
and application='Firefox'
and normalized_channel = '{norm_channel}'
and {build_version_field} in ('{current_version_crash}')
and profile_created>=12418 and profile_created<=20089 
and  MOD(ABS(FARM_FINGERPRINT(MD5(client_id))), SAMPLING.NBUCKS)=0
group by 1,2,3
),
--- TOTAL HOURS FROM FOLKS WHO CRASHED
--- TO COMPUTE CRASH RATE 
b2 as (select
client_id,
submission_date_s3 as date,
os as os,
sum(active_hours_sum) as usage,
sum(coalesce(crashes_detected_plugin_sum,0)) as cplugin
from telemetry.clients_daily_v6 HH left join SAMPLING
on HH.os = SAMPLING.sos and HH.normalized_channel = SAMPLING.chan
where
submission_date_s3 >='{current_version_release}'
and submission_date_s3 <= DATE_ADD(DATE '{current_version_release}', INTERVAL {nday} DAY)
and os  in ('Linux','Windows_NT','Darwin')
and app_name='Firefox'
and normalized_channel = '{norm_channel}'
and {app_version_field}='{current_version}'
-- and profile_creation_date>=12418 and profile_creation_date<=20089 
and  MOD(ABS(FARM_FINGERPRINT(MD5(client_id))), SAMPLING.NBUCKS)=0
group by 1,2,3
),
b as (
select 
b1.date,b1.os, 
count(distinct(case when b1.cmain>0 then b1.client_id else null end)) as dau_cm_crasher_cversion,
count(distinct(case when b1.ccontent>0  then b1.client_id else null end)) as dau_cc_crasher_cversion,
count(distinct(case when b2.cplugin>0 then b1.client_id else null end)) as dau_cp_crasher_cversion,
count(distinct(case when (b1.cmain>0 or b1.ccontent>0  or b2.cplugin>0)
                        then b1.client_id else null end)) as dau_call_crasher_cversion,
sum(case when b1.cmain>0 then b2.usage else 0 end) as usage_cm_crasher_cversion,
sum(case when b1.ccontent >0  then b2.usage else 0 end) as usage_cc_crasher_cversion,
sum(case when b2.cplugin >0 then b2.usage else 0 end) as usage_cp_crasher_cversion,
sum(case when (b1.cmain>0 or b1.ccontent>0 or b2.cplugin >0) then b2.usage else 0 end) as usage_call_crasher_cversion,
sum(cmain) as cmain,
sum(ccontent)  as ccontent,
sum(cplugin) as cplugin,
sum(cmain)+sum(ccontent) + sum(cplugin) as call
from b1 join b2 
on b1.client_id = b2.client_id and b1.os=b2.os and b1.date = b2.date
group by 1,2
),
d as (
select
A.date,A.os,A.usage_all, A.dau_all, A.usage_cversion, A.dau_cversion,
b.dau_cm_crasher_cversion,b.dau_cc_crasher_cversion,b.dau_cp_crasher_cversion,b.dau_call_crasher_cversion,
b.usage_cm_crasher_cversion,b.usage_cc_crasher_cversion,b.usage_cp_crasher_cversion,b.usage_call_crasher_cversion,
b.cmain,b.ccontent,b.cplugin,b.call
from b join A
on b.date=A.date and b.os=A.os
)
select * from d order by os, date
"

v65 <- list(
  list(v='65.0', d = "2019-01-29", till = '2019-02-28',c="release",ndays=72,app_version_field='app_version', build_version_field='build_version'),
  list(v='65.0.1', d = "2019-02-28", till='2019-03-19',c="release",ndays=72,app_version_field='app_version', build_version_field='build_version'))
 
v66 <- list(
  list(v='66.0', d = "2019-03-19", till = '2019-03-22',c="release",ndays=72,app_version_field='app_version', build_version_field='build_version'),
  list(v='66.0.1', d = "2019-03-22", till='2019-03-27',c="release",ndays=72,app_version_field='app_version', build_version_field='build_version'),
  list(v='66.0.2', d = "2019-03-27", till='2019-04-10',c="release",ndays=72,app_version_field='app_version', build_version_field='build_version'),
  list(v='66.0.3', d = "2019-04-10", till='2019-05-05', c="release",ndays=72,app_version_field='app_version', build_version_field='build_version'),
  list(v='66.0.4', d = "2019-05-05", till='2019-05-07',c="release",ndays=72,app_version_field='app_version', build_version_field='build_version'),
  list(v='66.0.5', d = "2019-05-07", till='2019-05-21',c="release",ndays=72,app_version_field='app_version', build_version_field='build_version'))

  
v67 <- list(
  list(v='67.0', d = "2019-05-21", till='2019-06-04',c="release",ndays=72,app_version_field='app_version', build_version_field='build_version'),
  list(v='67.0.1', d = "2019-06-04", till='2019-06-11',c="release",ndays=72,app_version_field='app_version', build_version_field='build_version'),
  list(v='67.0.2', d = "2019-06-11", till='2019-06-17',c="release",ndays=72,app_version_field='app_version', build_version_field='build_version'),
  list(v='67.0.3', d = "2019-06-18", till ='2019-06-19',c="release",ndays=72,crash_src='telemetry.crash_summary_v2',app_version_field='app_version', build_version_field='build_version'),
  list(v='67.0.4', d = "2019-06-20", till='2019-07-07', c='release',ndays=72, crash_src='telemetry.crash_summary_v2',app_version_field='app_version', build_version_field='build_version'))

v68 <- list(
  list(v='68.0', d = "2019-07-07", till = '2019-07-18',c="release",ndays=72,crash_src='telemetry.crash_summary_v2',app_version_field='app_version', build_version_field='build_version'),
  list(v='68.0.1', d = "2019-07-18", till = '2019-08-14',c="release",ndays=72,crash_src='telemetry.crash_summary_v2',app_version_field='app_version', build_version_field='build_version'),
  list(v='68.0.2', d = "2019-08-14", till = '2019-12-28',c="release",ndays=72,crash_src='telemetry.crash_summary_v2',app_version_field='app_version', build_version_field='build_version'))
  
g <- bq()

```

The above SQL query has some interesting features

- different sampling rates (100% for everything except Release/Windows which is
  33%)
- Data is pulled for a version number and for data between a start date (`d`)
  and for 72 days there after (`ndays`)
- the `till` variable above is used to define when that version is current. In
  other words, 68.0.1 is current from 2019-07-18 till 2019-08-14. We overlap by
  one day
- for beta we need to query by build\_version since this field is not present in
  crash summary
- we make some transformations in R code (see below after `g$q(...)`)
  -  define if the version is latest or not based on `till` variable
  - define crash rate e.g. ( 1 + main crashes)/total main hours experienced by
    main crashers (note total hours for if less than a minute we round to 0)
  - crash incidence is (1+ number of crashers)/total on that version 
  - `nvc` is hours proportion of total active hours on the current version a measure
  of adoption)  


```{r getData1,cache=TRUE,eval=FALSE,results='hide',message=FALSE, warning=FALSE}

library(glue) 
library(data.table)
isn <- function(s,r = 'telemetry.crash_summary_v1') if(is.null(s) || length(s)==0) r else s

dall.rel <- rbindlist(lapply(list(v65,v66,v67,v68),function(V){
  rbindlist(lapply(V,function(l){
    print(l)
    qrx <- glue(qr, app_version_field=l$app_version_field,current_version=l$v,current_version_crash=l$v,
                current_version_release=l$d, build_version_field=l$build_version_field,norm_channel = l$c,nday=l$ndays,crash_src=isn(l$crash_src),NBUCKS=3  )
    VVV<<-qrx
  f <- g$q(qrx,-1)
  f <- f[,":="(date=as.Date(date))]
  f[,":="(c_version = l$v, c_version_rel = l$d, isLatest=date<=l$till,t =as.numeric(date - as.Date(l$d)))][,]
  f <- f[, ":="(
    cmi=  (1+dau_cm_crasher_cversion)/dau_cversion,
    cmr = (1+cmain) / sapply(usage_cm_crasher_cversion,function(s) if( s< 60/3600){ 0 } else{ s}),
    cci = (1+dau_cc_crasher_cversion)/dau_cversion,
    ccr = (1+ccontent)/sapply(usage_cc_crasher_cversion,function(s) if(s< 60/3600){ 0}  else {s}),
    nvc=usage_cversion/usage_all,
    os=factor(os, levels=c("Linux","Darwin","Windows_NT"))
  )]
  f
}))}))



```

```{r betadata}

u <- local({
  u <- fromJSON(file="https://product-details.mozilla.org/1.0/firefox_history_development_releases.json")
  u <- data.table(versions=names(u), d= as.Date(unlist(u)),ndays=14,c='beta',crash_src='telemetry.crash_summary_v1')
  u$till= c(tail(u$d,-1),Sys.Date()+7)
  u[order(d),][grepl("b",versions),]
})

u2 <- u[grepl("(66|67|68|69)", versions),]

builds <- data.table(versions=c("65.0b3","65.0b4","65.0b5","65.0b6","65.0b7","65.0b8","65.0b9","65.0b10","65.0b11","65.0b12",
                      "66.0b3","66.0b4","66.0b5","66.0b6","66.0b7","66.0b8","66.0b9","66.0b10","66.0b11","66.0b12","66.0b13","66.0b14",
                      "67.0b3","67.0b4","67.0b5","67.0b6","67.0b7","67.0b8","67.0b9","67.0b10","67.0b11","67.0b12","67.0b13","67.0b14","67.0b15","67.0b16","67.0b17","67.0b18","67.0b19",
                      "68.0b3","68.0b4","68.0b5","68.0b6","68.0b7","68.0b8","68.0b9","68.0b10","68.0b11",'68.0b12','68.0b13','68.0b14',
                      '69.0b3','69.0b4',"69.0b5","69.0b6","69.0b7","69.0b8","69.0b9","69.0b10","69.0b11",'69.0b12','69.0b13',"69.0b14","69.0b15"
                                 ),
                     buildid = c('20181210164452','20181211223337','20181217180946','20181220174318','20181227144402','20190103150357','20190107180200','20190110221328','20190114172331',
                                 '20190117232427'
                                 , '20190128143734','20190131191227','20190204181317','20190207161357','20190211185957','20190214195736','20190218131312','20190221160854','20190225143245',
                                  '20190228180200','20190304101322','20190307095232',
                                  '20190318154932','20190321164326,20190322012752','20190325125126','20190328152334','20190331141835','20190404040123,20190404130536','20190408123043',
                                  '20190411084603','20190415085659','20190418160535','20190422163745','20190424140259','20190429125729','20190502224831,20190502232159','20190505015947',
                                  '20190506235559','20190509185224',
                                 '20190521110747','20190523115432','20190527103257','20190529145824','20190603181408','20190606101422','20190610153228','20190613141208','20190617172838',
                                 '20190619234730','20190624133534','20190627143605',
                                 '20190708182549','20190711205826,20190712011116','20190715173502','20190718172058','20190722201635','20190725174626','20190729190604,20190730004747',
                                 '20190801185445','20190805120428','20190807220259','20190812173625',"20190815163925","20190819184224"
                                  ))
u2[d > '2019-06-18',crash_src := 'telemetry.crash_summary_v2']
u2 <- merge(u2,builds, by='versions')
u2 <- u2[order(d),]


add_fields <- function(x, current_version, d,till ){
  x <- x[,":="(date=as.Date(date))]
  x[,":="(date=as.Date(date),c_version = current_version, c_version_rel = d, isLatest=date<=till,t =as.numeric(date - as.Date(d)))][,]
  x<- x[, ":="(
    cmi=  (1+dau_cm_crasher_cversion)/dau_cversion,
    cmr = (1+cmain) / sapply(usage_cm_crasher_cversion,function(s) {if( s< 60/3600){ 0 } else{ s}}),
    cci = (1+dau_cc_crasher_cversion)/dau_cversion,
    ccr = (1+ccontent)/sapply(usage_cc_crasher_cversion,function(s) {if( s< 60/3600){ 0 } else{ s}}),
    nvc=usage_cversion/usage_all,
    os=factor(os, levels=c("Linux","Darwin","Windows_NT")),
    c_version_rel = as.Date(c_version_rel)
  )]
  x
}


dall.beta <- rbindlist(lapply(c('66','67','68','69'),function(xx){
  u2[grepl(xx,versions),][, {
    print(.SD);print(.BY)
    qf <- glue(qr, current_version=.BY$versions,current_version_crash=buildid,
               current_version_release=d, norm_channel = c,
               app_version_field = 'app_display_version', build_version_field='build_id',
               nday=ndays,crash_src=isn(crash_src),NBUCKS=1
               )
    qff <- g$q(qf,-1)
    if(nrow(qff) > 0)
      add_fields(qff,.BY$versions,d,till)
  },by=versions]
}))


```

We only want to use data where `nvc` is before the peak. Profiles adopt to  a
version, `nvc` increases and then decreases. We want data _before_ we reach the
peak. We take data upto this max. if the version is current but the max is
before the end of last day we use data while it's current.



```{r}
## Data was missing in may

dall.rel2 <- dall.rel[date<'2019-08-14',][!c_version %in% c('66.0.4','66.0.5'),][, {
  ## Take the last day we saw the max
  index <- which.max(nvc)
  s <- (1:.N)[ isLatest]
  if(length(s) > 0){
   whenStoppedBeingLatest <- max( s )
  } else whenStoppedBeingLatest <- -1
  if(index<whenStoppedBeingLatest) index <- whenStoppedBeingLatest
  .SD[1:whenStoppedBeingLatest,]
  .SD[1:index,]
  },by=list(os,c_version)]

dall.beta2 <- dall.beta[!c_version %in% c('67.0b17','67.0b18'),][, {
  ## Take the last day we saw the max
  index <- which.max(nvc)
  s <- (1:.N)[ isLatest]
  if(length(s) > 0){
   whenStoppedBeingLatest <- max( s )
  } else whenStoppedBeingLatest <- -1
  if(index<whenStoppedBeingLatest) index <- whenStoppedBeingLatest
  .SD[1:whenStoppedBeingLatest,]
  },by=list(os,c_version)]

dall.rel2[, major := factor(sapply(c_version,function(s) head(strsplit(s,"\\.")[[1]],1)))]
dall.rel2[, minor := factor(sapply(c_version,function(s) tail(strsplit(s,"\\.")[[1]],1)))]

dall.beta2[, major
           := factor(sapply(c_version,function(s) head(strsplit(s,"\\.0b")[[1]],1)))]
dall.beta2[, minor := factor(sapply(c_version,function(s) tail(strsplit(s,"\\.0b")[[1]],1)))]

```


Current and last two versions:

```{r}

d.rel <- dall.rel2[major %in% c("66","67","68"),][,idx := 1:.N]
d.beta <- dall.beta2[major %in% c('67','68','69'),][,idx := 1:.N]
d.rel <- d.rel[nvc > 0,]
d.beta <- d.beta[nvc > 0]
d.rel[, ":="(nvc.logit=boot::logit(nvc),cmr.wt = 1*(cmain >0), ccr.wt = 1*(ccontent > 0))]
d.beta[, ":="(nvc.logit=boot::logit(nvc),cmr.wt = 1*(cmain >0), ccr.wt = 1*(ccontent > 0))]


```


Commented models appear to overfit. In future:

- do we need two older versions?
- Can i use the output of this model to perform something like posterior passing
  on a smaller data set .e.g this version and last version?)


```{r}

library(parallel)


ffunc <- function(M,D)  brm(M,data=D, chains = 4, control = list(adapt_delta = 0.999, max_treedepth=12), cores = 4)
make.a.model <- function(data,wh,skew=FALSE){
  if(wh=="cmr"){
      M0 <- bf( log(cmain+1) |weights(cmr.wt)   ~  os+offset(log( usage_cm_crasher_cversion+1/60))  + s(nvc,m=1,by=os) + (1+os|c_version), sigma ~ os+s(nvc,m=1))
      # M0 <- bf( log(1+cmain) | weights(cmr.wt)   ~  os + os*poly(log(usage_cm_crasher_cversion+1/60),2)+os*poly(nvc.logit,2)  + (1+os|c_version), sigma ~   os + s(nvc.logit, m=1))
  }
  if(wh=='ccr'){
      M0 <- bf( log(ccontent+1) | weights(ccr.wt)   ~  os+offset(log( usage_cc_crasher_cversion+1/60))  + s(nvc,m=1,by=os) + (1+os|c_version), sigma ~ os+s(nvc,m=1))
      # M0 <- bf( log(1+ccontent) | weights(cmr.wt)   ~  os + os*poly(log(usage_cc_crasher_cversion+1/60),2)+os*poly(nvc.logit,2)  + (1+os|c_version), sigma ~   os + s(nvc.logit, m=1))
  }
  if(wh=='cmi'){
       M0<- bf( log(1+dau_cm_crasher_cversion)   ~   os+ offset(log( dau_cversion)) + s(nvc,m=1,by=os) + (1+os|c_version), sigma ~ os+s(nvc,m=1))
       # M0 <- bf( log(1+dau_cm_crasher_cversion)    ~  os + os*poly(log(dau_cversion),2)+os*poly(nvc.logit,2)  + (1+os|c_version), sigma ~   os + s(nvc.logit, m=1))
  }
  if(wh=='cci'){
     M0<- bf( log(1+dau_cc_crasher_cversion)   ~   os+ offset(log( dau_cversion))  + s(nvc,m=1,by=os) + (1+os|c_version), sigma ~ os+s(nvc,m=1))
     # M0 <- bf( log(1+dau_cc_crasher_cversion)    ~  os + os*poly(log(dau_cversion),2)+os*poly(nvc.logit,2)  + (1+os|c_version), sigma ~   os + s(nvc.logit, m=1))
  }
  ffunc(M0,data)
}

getPredictions <- function(M,D, wh,givenx=NULL,COUNT=FALSE){
  if(is.null(givenx)){
    x <- predict(M,newdata=D,summary=FALSE)
  }else{
    x <- givenx
  }
  if(COUNT){
    return (exp(t(x)-1))
  }
  if(wh=='cmr'){
    r <- exp( t(x) - D[, log( usage_cm_crasher_cversion+1/60)])
  }
  if(wh=='ccr'){
    r <- exp(t(x) -  D[, log( usage_cc_crasher_cversion+1/60)])
  }
  if(wh=='cmi'){
    r <- exp(t(x) -  D[, log( dau_cversion)])
    }
  if(wh=='cci'){
    r <- exp(t(x) - D[, log( dau_cversion)])
  }
  r
}
 

library(future)
plan(multicore)

slackr("RELEASE CHAINS STARTING")
cr.cm.rel.f <- future({ make.a.model(d.rel,'cmr') })
cr.cc.rel.f <- future({ make.a.model(d.rel,'ccr') })
ci.cm.rel.f <- future({ make.a.model(d.rel,'cmi') })
ci.cc.rel.f <- future({ make.a.model(d.rel,'cci') })

cr.cm.rel <- value(cr.cm.rel.f)
cr.cc.rel <- value(cr.cc.rel.f)
ci.cm.rel <- value(ci.cm.rel.f)
ci.cc.rel <- value(ci.cc.rel.f)
slackr("RELEASE CHAINS DONE")

slackr("BETA CHAINS STARTING")
cr.cm.beta.f <- future({ make.a.model(d.beta,'cmr') })
cr.cc.beta.f <- future({ make.a.model(d.beta,'ccr') })
ci.cm.beta.f <- future({ make.a.model(d.beta,'cmi') })
ci.cc.beta.f <- future({ make.a.model(d.beta,'cci') })
cr.cm.beta <- value(cr.cm.beta.f)
cr.cc.beta <- value(cr.cc.beta.f)
ci.cm.beta <- value(ci.cm.beta.f)
ci.cc.beta <- value(ci.cc.beta.f)
slackr("BETA CHAINS DONE!")



## I use a 1% trimmed mean because some of the posterios especially when nvc is small
## jave crazy large outliers.

TR <- 1/100/2
CENT <- function(s)  mean(s, trim=TR)
getLowsAndHighs <- function(D,mdl.rm,mdl.rc,mdl.im,mdl.ic){
  getLowHi <- function(x,names,trans){
    x <- rbindlist(apply(x,1,function(s){
      data.table(lo90 = trans(quantile(s,0.05)), mean = CENT(trans(s)), hi90=quantile(trans(s),0.95))
    }))
    setnames(x,names)
  }
  pm <- getPredictions(mdl.rm, D, 'cmr')
  pc <- getPredictions(mdl.rc, D, 'ccr')
  cmrpreds <- getLowHi(pm,trans=function(s) s,names=c("cmr.lo90","cmr.mean","cmr.hi90"))
  ccrpreds <- getLowHi(pc,trans=function(s) s,names=c("ccr.lo90","ccr.mean","ccr.hi90"))
  cavgrpreds <- getLowHi((pm+pc)/2,trans=function(s) s,names=c("cavgr.lo90","cavgr.mean","cavgr.hi90"))
  pm <- getPredictions(mdl.im, D, 'cmi')
  pc <- getPredictions(mdl.ic, D, 'cci')
  cmipreds <- getLowHi(pm,trans=function(s) s,names=c("cmi.lo90","cmi.mean","cmi.hi90"))
  ccipreds <- getLowHi(pc,trans=function(s) s,names=c("cci.lo90","cci.mean","cci.hi90"))
  cavgipreds <- getLowHi((pm+pc)/2,trans=function(s) s,names=c("cavgi.lo90","cavgi.mean","cavgi.hi90"))
  cbind(cmrpreds,ccrpreds,cavgrpreds, cmipreds, ccipreds, cavgipreds)
}

CENT <- function(s)  median(s) #mean(s, trim=TR)
getBetaTrend <- function(D,mdl.rm,mdl.rc,mdl.im,mdl.ic){
  getLowHi <- function(x,names,trans){
    x <- rbindlist(apply(x,1,function(s){
      data.table(lo90 = trans(quantile(s,0.05)), mean = CENT(trans(s)), hi90=quantile(trans(s),0.95))
    }))
    setnames(x,names)
  }
  cversions  = D[, list(l=1),by=list(os,c_version)][,l := NULL]
  pm <- cbind(D[, list(os,c_version, usage_cm_crasher_cversion)],data.table(getPredictions(mdl.rm, D, 'cmr',COUNT=TRUE)))[, {
    f <- data.table(t(apply(.SD,2,sum,drop=FALSE)))
    (1+f[,2:ncol(f), with=FALSE])/ (1/60+f[,1,with=FALSE][[1]])
  },   by=list(os,c_version)][, ":="(c_version = NULL, os=NULL)]
  print("cmr done")
  pc <- cbind(D[, list(os,c_version, usage_cc_crasher_cversion)],data.table(getPredictions(mdl.rc, D, 'ccr',COUNT=TRUE)))[, {
    f <- data.table(t(apply(.SD,2,sum,drop=FALSE)))
    (1+f[,2:ncol(f), with=FALSE])/ (1/60+f[,1,with=FALSE][[1]])
  },   by=list(os,c_version)][, ":="(c_version = NULL, os=NULL)]
  print("ccr done")
  cmrpreds <- getLowHi(pm,trans=function(s) s,names=c("cmr.lo90","cmr.mean","cmr.hi90"))
  ccrpreds <- getLowHi(pc,trans=function(s) s,names=c("ccr.lo90","ccr.mean","ccr.hi90"))
  cavgrpreds <- getLowHi((pm+pc)/2,trans=function(s) s,names=c("cavgr.lo90","cavgr.mean","cavgr.hi90"))
  pm <- cbind(D[, list(os,c_version, dau_cversion)],data.table(getPredictions(mdl.im, D, 'cmi',COUNT=TRUE)))[, {
    f <- data.table(t(apply(.SD,2,sum,drop=FALSE)))
    (1+f[,2:ncol(f), with=FALSE])/ f[,1,with=FALSE][[1]]
  },   by=list(os,c_version)][, ":="(c_version = NULL, os=NULL)]
  print("cmi done")
  pc <- cbind(D[, list(os,c_version,dau_cversion )],data.table(getPredictions(mdl.ic, D, 'cci',COUNT=TRUE)))[, {
    f <- data.table(t(apply(.SD,2,sum,drop=FALSE)))
    (1+f[,2:ncol(f), with=FALSE])/ f[,1,with=FALSE][[1]]
  },   by=list(os,c_version)][, ":="(c_version = NULL, os=NULL)]
  print("cci done")
  cmipreds <- getLowHi(pm,trans=function(s) s,names=c("cmi.lo90","cmi.mean","cmi.hi90"))
  ccipreds <- getLowHi(pc,trans=function(s) s,names=c("cci.lo90","cci.mean","cci.hi90"))
  cavgipreds <- getLowHi((pm+pc)/2,trans=function(s) s,names=c("cavgi.lo90","cavgi.mean","cavgi.hi90"))
  cbind(cversions,cmrpreds,ccrpreds,cavgrpreds, cmipreds, ccipreds, cavgipreds)
}

getRelDiff <- function(crm.model,crc.model,cim.model,cic.model,current.data,current.data.modified,CUT=0.35){
  H <- function(S,names){
    x <- data.table(h=apply(S,1,function(s) { a <-mean(s > CUT); if(is.na(a)) 0 else a}))
    setnames(x,names)
    x
  }
  tvm <- getPredictions(NULL, current.data,'cmr',given=predict(crm.model,summary=FALSE, newdata=current.data))
  pvm <- getPredictions(NULL, current.data.modified, 'cmr',given=predict(crm.model,summary=FALSE, newdata=current.data.modified))
  tvc <- getPredictions(NULL, current.data, 'ccr', given=predict(crc.model,summary=FALSE, newdata=current.data))
  pvc <- getPredictions(NULL, current.data.modified, 'ccr', given=predict(crc.model,summary=FALSE, newdata=current.data.modified))
  trans <- function(s) s  #function(x) x
  cmr=H(  (trans(tvm) - trans(pvm))/trans(pvm),names=c("cmr.reg.prob"))
  ccr=H(  (trans(tvc) - trans(pvc))/trans(pvc),names=c("ccr.reg.prob"))
  tv1 <- (tvc+tvm)/2;pv1 <- (pvc+pvm)/2
  cavgr <- H( (trans(tv1) - trans(pv1))/trans(pv1),names=c("cavgr.reg.prob"))
  tvm <- getPredictions(NULL, current.data,'cmr',given=predict(cim.model,summary=FALSE, newdata=current.data))
  pvm <- getPredictions(NULL, current.data.modified, 'cmr',given=predict(cim.model,summary=FALSE, newdata=current.data.modified))
  tvc <- getPredictions(NULL, current.data, 'ccr', given=predict(cic.model,summary=FALSE, newdata=current.data))
  pvc <- getPredictions(NULL, current.data.modified, 'ccr', given=predict(cic.model,summary=FALSE, newdata=current.data.modified))
  trans <- function(x) x
  cmi=H(  (trans(tvm) - trans(pvm))/trans(pvm),names=c("cmi.reg.prob"))
  cci=H(  (trans(tvc) - trans(pvc))/trans(pvc),names=c("cci.reg.prob"))
  tv1 <- (tvm+tvc)/2;pv1 <- (pvm+pvc)/2
  cavgi <- H( (trans(tv1) - trans(pv1))/trans(pv1),names=c("cavgi.reg.prob"))
  cbind(current.data[,list(os,date,c_version)],cmr, ccr,cavgr, cmi,cci,cavgi)
}



##################################################
## For Release
##################################################

rel.current.version <- '68.0.1'
rel.prev.version <- '68.0'
rel.current.data <- d.rel[c_version==rel.current.version,][order(os, date),]
rel.current.data.modified <- data.table(data.frame(rel.current.data))[, c_version := rel.prev.version]

lowhigh.rel <- getLowsAndHighs(d.rel,cr.cm.rel,cr.cc.rel,ci.cm.rel,ci.cc.rel)
reldiff.rel <- getRelDiff(cr.cm.rel,cr.cc.rel,ci.cm.rel,ci.cc.rel, rel.current.data,rel.current.data.modified)

rel.posts <- cbind(d.rel[,list(date,cmr.wt,ccr.wt,c_version, os,nvc,cmr,ccr,cmi,cci)],lowhigh.rel)
rel.posts <- merge(rel.posts,reldiff.rel,all.x=TRUE,by=c("os","date","c_version"))

rel.summary <- rel.posts[c_version==rel.current.version,][date==max(date),]

H0 <- function(nvc,l,h){
  return( nvc > 0.2)
}
SPAN_L <- 2
rel.posts <- merge(rel.posts,rel.posts[,{
  i <- 1:.N
  cavgr <- (cmr+ccr)/2; cavgi <- (cmi+cci)/2
  cmr.fit <- loess(cmr.mean  ~ i,span=SPAN_L,weights=H0(nvc,cmr.lo90,cmr.hi90))$fitted
  ccr.fit <- loess(ccr.mean ~ i, span=SPAN_L, weights=H0(nvc,ccr.lo90,ccr.hi90))$fitted
  cavgr.fit <- loess(cavgr.mean ~ i, span=SPAN_L, weights=H0(nvc,cavgr.lo90,cavgr.hi90))$fitted
  cmi.fit <- loess(cmi.mean  ~ i, span=SPAN_L, weights=H0(nvc,cmi.lo90,cmi.hi90))$fitted
  cci.fit <- loess(cci.mean ~ i, span=SPAN_L, weights=H0(nvc,cci.lo90,cci.hi90))$fitted
  cavgi.fit <- loess(cavgi.mean ~ i, span=SPAN_L, weights=H0(nvc,cavgi.lo90,cavgi.hi90))$fitted
  list(date=date,c_version=c_version,cmr.loess=cmr.fit,
       ccr.loess=ccr.fit, cavgr.loess=cavgr.fit,
       cmi.loess=cmi.fit, cci.loess=cci.fit, cavgi.loess=cavgi.fit)
  }, by=os], by=c("os","date","c_version"))

###################################################
## For Beta
###################################################
beta.current.version <- '69.0b15'
beta.prev.version <- '69.0b14'
beta.current.major <- '69'
beta.prev.major <- '68'
beta.current.data <- d.beta[c_version==beta.current.version,][order(os, date),]
beta.current.data.modified <- data.table(data.frame(beta.current.data))[, c_version := beta.prev.version]

lowhigh.beta <- getLowsAndHighs(d.beta,cr.cm.beta,cr.cc.beta,ci.cm.beta,ci.cc.beta)
reldiff.beta <- getRelDiff(cr.cm.beta,cr.cc.beta,ci.cm.beta,ci.cc.beta, beta.current.data,beta.current.data.modified)
beta.posts <- cbind(d.beta[,list(date,cmr.wt,ccr.wt,c_version, os,nvc,cmr,ccr,cmi,cci)],lowhigh.beta)
beta.posts <- merge(beta.posts,reldiff.beta,all.x=TRUE,by=c("os","date","c_version"))

beta.summary <- beta.posts[c_version==beta.current.version,][date==max(date),]
beta.trend3 <- getBetaTrend(d.beta,cr.cm.beta,cr.cc.beta,ci.cm.beta,ci.cc.beta)
beta.trend3[, ":="(major =  (sapply(c_version,function(s) head(strsplit(s,"\\.0b")[[1]],1))),
                   minor = (sapply(c_version,function(s) tail(strsplit(s,"\\.0b")[[1]],1))))]
beta.trend2 <- beta.trend3[major %in% c(beta.current.major,beta.prev.major),][order(os,as.numeric(as.character(major)),as.numeric(as.character(minor))),]
beta.trend2 <- merge(beta.trend4,  beta.posts[, {
  tail(.SD,1)[, list(nvc=nvc)]
},by=list(os,c_version)], by=c("os","c_version"))[order(os,as.numeric(as.character(major)),as.numeric(as.character(minor))),]

#beta.trend <- beta.posts[, {
#  tail(.SD,1)
#},by=list(os,c_version)]
#beta.trend[, major := (sapply(c_version,function(s) head(strsplit(s,"\\.0b")[[1]],1)))]
#beta.trend[, minor := (sapply(c_version,function(s) tail(strsplit(s,"\\.0b")[[1]],1)))]
#beta.trend2 <-  beta.trend[major %in% c(beta.current.major,beta.prev.major),][order(as.numeric(as.character(major)),as.numeric(as.character(minor))),]


## SAVE
u <- getwd()
setwd("visual_demo/data/")
write.csv(rel.posts, "rel.posts.csv")
write.csv(rel.summary,"rel.summary.csv")
write.csv(beta.posts,"beta.posts.csv")
write.csv(beta.summary,"beta.summary.csv")
write.csv(beta.trend2, "beta.trend.csv")
setwd(u);rm(u)

```

```{r eval=FALSE}
render("./report.2.Rmd")
render_site("./visual_demo/")
```


```{r}
## Random Plots


H1 <- rel.posts[os=='Darwin' & date %between% c("2019-07-27","2019-08-12") ,]
ggplot(H1, aes(date,cmr.mean))+geom_point()+geom_line()+ geom_ribbon(data=H1,aes(x=date, ymin=cmr.lo90,ymax=cmr.hi90),alpha=0.3)
dev.off()


H1 <- beta.posts[os=='Windows_NT' & date %between% c("2019-07-25","2019-08-12") ,]
ggplot(H1, aes(date,cmr.mean))+geom_point()+geom_line()+ geom_ribbon(data=H1,aes(x=date, ymin=cmr.lo90,ymax=cmr.hi90),alpha=0.3)
ggplot(H1, aes(date,cmr))+geom_point()+geom_line()
dev.off()

H1 <- rel.posts[os=='Windows_NT',]
ggplot(H1, aes(date,cci.mean))+geom_line()+ geom_ribbon(data=H1,aes(x=date, ymin=cci.lo90,ymax=cci.hi90),alpha=0.3)+
  geom_line(data=H1,aes(date,cci.loess),color='red')
dev.off()

H2 <- H1[!is.na(cmi.rd.m),]
ggplot(H2, aes(date,cmr.rd.m))+geom_line()+ geom_ribbon(data=H2,aes(x=date, ymin=cmr.rd.lo,ymax=cmr.rd.hi),alpha=0.3)
dev.off()

A <- rel.posts[os=='Windows_NT' & c_version=='68.0.1',][order(nvc),][nvc > 0.1,]
B <- rel.posts[os=='Windows_NT' & c_version=='68.0',][order(nvc),][nvc > 0.1,]

ggplot()+
  geom_line(data=A,aes(nvc,cmr.mean),color='blue')+
  geom_ribbon(data=A,aes(x=nvc, ymin=cmr.lo90,ymax=cmr.hi90),alpha=0.3)+
  geom_line(data=B,aes(nvc,cmr.mean),color='red')+
  geom_ribbon(data=B,aes(x=nvc, ymin=cmr.lo90,ymax=cmr.hi90),alpha=0.3)
ggplot(A, aes(date,cmr.rd.m))+geom_line()+ geom_ribbon(data=A,aes(x=date, ymin=cmr.rd.lo,ymax=cmr.rd.hi),alpha=0.3)
dev.off()

A <- beta.posts[os=='Darwin' & c_version=='69.0b12',][order(nvc),]
B <- beta.posts[os=='Darwin' & c_version=='69.0b11',][order(nvc),]

ggplot()+
  geom_line(data=A,aes(nvc,cmr.mean),color='blue')+
  geom_ribbon(data=A,aes(x=nvc, ymin=cmr.lo90,ymax=cmr.hi90),alpha=0.3)+
  geom_line(data=B,aes(nvc,cmr.mean),color='red')
  geom_ribbon(data=B,aes(x=nvc, ymin=cmr.lo90,ymax=cmr.hi90),alpha=0.3)
ggplot(A, aes(date,cmr.rd.m))+geom_line()+ geom_ribbon(data=A,aes(x=date, ymin=cmr.rd.lo,ymax=cmr.rd.hi),alpha=0.3)
dev.off()
```


```{r pp1,eval=TRUE}
pp_check(cr.cc.rel, type='stat_grouped', group='os')
pp_check(cr.cm.rel, type='stat_grouped', group='os')
pp_check(cr.cm.beta, type='stat_grouped', group='os')
pp_check(cr.cc.beta, type='stat_grouped', group='os')
```


```{r pp2,eval=TRUE}
pp_check(ci.cm.rel, type='stat_grouped', group='os')
pp_check(ci.cc.rel, type='stat_grouped', group='os')
pp_check(ci.cm.beta, type='stat_grouped', group='os') 
pp_check(ci.cc.beta, type='stat_grouped', group='os')
```

```{r echo=TRUE,eval=TRUE}
rel.posts[!is.na(cmr) & cmr !=Inf & cmr<10,cor(cmr,cmr.mean),by=os]
rel.posts[!is.na(ccr) & ccr !=Inf & ccr<10,cor(ccr,ccr.mean),by=os]
beta.posts[!is.na(cmr) & cmr !=Inf & cmr<10,cor(cmr,cmr.mean),by=os]
beta.posts[!is.na(ccr) & ccr !=Inf & ccr<10,cor(ccr,ccr.mean),by=os]


rel.posts[,cor(cmi,cmi.mean),by=os]
rel.posts[,cor(cci,cci.mean),by=os]
beta.posts[,cor(cmi,cmi.mean),by=os]
beta.posts[,cor(cci,cci.mean),by=os]


```



## Quick Plots

We see the mean content and main crash rate relationship vs. nvc

- change in means (shape changes with os / metric)
- variance drops also (irrespective of os or metric)


```{r}
x <- dall.rel2[, list(c_version,major,minor,os,nvc, cmr, ccr,cmi,cci)]

pdf("Rplots.pdf",width=10)
ggplot(x[ccr<quantile(ccr,0.95) &os=='Windows_NT',], aes(nvc, ccr,color=os))+geom_point()+geom_smooth()+labs(title='Content CR')
ggplot(x[cmr<quantile(cmr,0.95),], aes(nvc, cmr,color=os))+geom_point()+geom_smooth()+labs(title='MAIN CR')
ggplot(x[cmi<quantile(cmi,0.95),], aes(nvc, cmi,color=os))+geom_point()+geom_smooth()+labs(title='Content CI')
ggplot(x[cci<quantile(cci,0.95),], aes(nvc, cci,color=os))+geom_point()+geom_smooth()+labs(title='Main CI')

z <- x[, list(x=mean(ccr), s=sd(ccr)),by=list(nvc.cut=as.numeric(cut(nvc, quantile(nvc,0:10/10))))]
ggplot(z, aes(nvc.cut, x))+geom_point()+geom_smooth()
ggplot(z, aes(nvc.cut, s))+geom_point()+geom_smooth()
z <- x[, list(x=mean(cmr), s=sd(cmr)),by=list(nvc.cut=as.numeric(cut(nvc, quantile(nvc,0:10/10))))]
ggplot(z, aes(nvc.cut, x))+geom_point()+geom_smooth()
ggplot(z, aes(nvc.cut, s))+geom_point()+geom_smooth()
z <- x[, list(x=mean(cmi), s=sd(cmi)),by=list(nvc.cut=as.numeric(cut(nvc, quantile(nvc,0:10/10))))]
ggplot(z, aes(nvc.cut, x))+geom_point()+geom_smooth()
ggplot(z, aes(nvc.cut, s))+geom_point()+geom_smooth()
z <- x[, list(x=mean(cci), s=sd(cci)),by=list(nvc.cut=as.numeric(cut(nvc, quantile(nvc,0:10/10))))]
ggplot(z, aes(nvc.cut, x))+geom_point()+geom_smooth()
ggplot(z, aes(nvc.cut, s))+geom_point()+geom_smooth()

```
